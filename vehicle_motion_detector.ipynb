{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting motion of Vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"input/input_video.mp4\")\n",
    "\n",
    "# UNCOMMENT THE NEXT LINE TO SAVE THE VIDEO --------------------------------------------------------------------\n",
    "writer = cv2.VideoWriter('output/result.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 22, (1280,720))  \n",
    "\n",
    "\n",
    "# reading first frame\n",
    "ret, frame1 = cap.read() \n",
    "\n",
    "while cap.isOpened():\n",
    "    flag = False\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # absolute difference between two consecutive frame\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    \n",
    "    \n",
    "    # gray scaling image\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    blur = cv2.GaussianBlur(gray, (3,3), 12)\n",
    "\n",
    "    ret, thresh = cv2.threshold(blur, 34, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    \n",
    "    # applying 3 sets of erode-dialate pairs to grab the fine details\n",
    "    \n",
    "    # the following filters have different kernel size, iterations\n",
    "    \n",
    "    # these were varied in wide ranges to find the optimal value so as to extract best information from the video.\n",
    "    # these values may not apply to every video and might require some tweaking\n",
    "    \n",
    "    # this lacking of generalized output is acceptable since we are not using any classifier or trained model to detect vehicles.\n",
    "    # we are just using change in pixel values\n",
    "    \n",
    "    # the outputs varys with weather conditions at that time(vehicle shadows interferes), angle at which the video is taken, heavy or light traffic \n",
    "    # as in heavy traffic, vehicles tend to merge into one another\n",
    "    # Falling of shadows of one vehicles onto another vehicle is another constraint. there is not much different in pixel value and thus those vhicle are percieevd as one. \n",
    "    \n",
    "    \n",
    "    #  erode(4,4)*1 --> dialate(8,8)*1 --> erode(7,7)*1 --> dialate(7,7)*1 --> erode(9,9)*1 --> dialate(9,9)*2\n",
    "    \n",
    "    kernel = np.ones((4,4),dtype=np.uint8)\n",
    "    erode1 = cv2.erode(thresh, kernel, iterations = 1)\n",
    "    \n",
    "    kernel = np.ones((8,8),dtype=np.uint8)\n",
    "    dialate1 = cv2.dilate(erode1,kernel,iterations = 1)\n",
    "    #\n",
    "    kernel = np.ones((8,8),dtype=np.uint8)\n",
    "    dialate1 = cv2.dilate(erode1,kernel,iterations = 1)\n",
    "    #\n",
    "    \n",
    "    kernel = np.ones((7,7),dtype=np.uint8)\n",
    "    erode2 = cv2.erode(dialate1, kernel, iterations = 1)\n",
    "    \n",
    "    kernel = np.ones((7,7),dtype=np.uint8)\n",
    "    dialate2 = cv2.dilate(erode2,kernel,iterations = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    kernel = np.ones((9,9),dtype=np.uint8)\n",
    "    erode3 = cv2.erode(dialate2, kernel, iterations = 1)\n",
    "    \n",
    "    kernel = np.ones((9,9),dtype=np.uint8)\n",
    "    dialate3 = cv2.dilate(erode3,kernel,iterations = 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # extracting external contours\n",
    "    contours, hierarchy = cv2.findContours(dialate3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    final = frame2.copy()\n",
    "    for cnt in contours:\n",
    "        flag = True\n",
    "        (x,y,w,h) = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(final, (x, y), (x+w, y+h), (12,232,21), 2)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('frames', frame2)\n",
    "    if flag:\n",
    "        cv2.imshow('final', final)\n",
    "        # UNCOMMENT THE NEXT LINE TO SAVE THE VIDEO --------------------------------------------------------------------\n",
    "        writer.write(final)\n",
    "        \n",
    "\n",
    "    \n",
    "    frame1 = frame2\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "# UNCOMMENT THE NEXT LINE TO SAVE THE VIDEO --------------------------------------------------------------------\n",
    "writer.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
